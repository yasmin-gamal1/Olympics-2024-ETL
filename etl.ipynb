{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "import plotly.express as px\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Database connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnxn_str = (\n",
    "    \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "    \"Server=Yasmin-Gamal;\"\n",
    "    \"Database=Football;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")\n",
    "\n",
    "servername = 'Yasmin-Gamal'\n",
    "dbname = 'Football'\n",
    "engine = create_engine('mssql+pyodbc://@' + servername + '/' + dbname + '?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyodbc\n",
    "\n",
    "\n",
    "# In[119]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# In[237]:\n",
    "\n",
    "\n",
    "cnxn_str = (\n",
    "    \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "    \"Server=Yasmin-Gamal;\"\n",
    "    \"Database=Football_DB;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")\n",
    "\n",
    "\n",
    "# In[238]:\n",
    "\n",
    "\n",
    "cnxn=pyodbc.connect(cnxn_str)\n",
    "\n",
    "\n",
    "# In[239]:\n",
    "\n",
    "\n",
    "cursor=cnxn.cursor()\n",
    "\n",
    "\n",
    "# In[240]:\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "# connection_string = (\n",
    "#     \"mssql://;\"\n",
    "#     \"Server=Yasmin-Gamal;\"\n",
    "#     \"Database=football;\"\n",
    "#     \"Trusted_Connection=yes;\"\n",
    "#     \"driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "# )\n",
    "\n",
    "# engine = create_engine(connection_string)\n",
    "\n",
    "# username='YASMIN-GAMAL\\\\acer'\n",
    "# print(username)\n",
    "servername='Yasmin-Gamal'\n",
    "dbname= 'Football'\n",
    "engine=create_engine('mssql+pyodbc://@' + servername + '/' + dbname + '?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server')\n",
    "\n",
    "\n",
    "# engine = create_engine('mssql+pyodbc://'+username+'@'+server+'/'+database+'?driver=ODBC+Driver+17+for+SQL+Server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_incremental_data():\n",
    "    \n",
    "        matches_path = r\"C:\\Users\\sweet\\Desktop\\DS Atos intern\\Atos DS Task 1\\Matches.csv\"\n",
    "        players_path = r\"C:\\Users\\sweet\\Desktop\\DS Atos intern\\Atos DS Task 1\\Players.csv\"\n",
    "        teams_path = r\"C:\\Users\\sweet\\Desktop\\DS Atos intern\\Atos DS Task 1\\Teams.csv\"\n",
    "        playerstats_path = r\"C:\\Users\\sweet\\Desktop\\DS Atos intern\\Atos DS Task 1\\PlayerStats.csv\"\n",
    "        transferhistory_path = r\"C:\\Users\\sweet\\Desktop\\DS Atos intern\\Atos DS Task 1\\PlayerTransfers.csv\"\n",
    "\n",
    "\n",
    "        # In[225]:\n",
    "\n",
    "\n",
    "        import pandas as pd\n",
    "        # Load data from CSV files into DataFrames\n",
    "        df_matches = pd.read_csv(matches_path)\n",
    "        df_players = pd.read_csv(players_path)\n",
    "        df_teams = pd.read_csv(teams_path)\n",
    "        df_playerstats = pd.read_csv(playerstats_path)\n",
    "        df_transferhistory = pd.read_csv(transferhistory_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "         df_teams.to_sql(name='Teams', con=engine, if_exists='replace', index=False)\n",
    "        except Exception as e: print(e)\n",
    "\n",
    "\n",
    "        # In[244]:\n",
    "\n",
    "\n",
    "        try:\n",
    "         df_players.to_sql(name='Players', con=engine, if_exists='replace', index=False)\n",
    "        except Exception as e: print(e)\n",
    "\n",
    "\n",
    "        # In[245]:\n",
    "\n",
    "\n",
    "        try:df_matches.to_sql(name='Matches', con=engine, if_exists='replace', index=False)\n",
    "        except Exception as e: print(e)\n",
    "\n",
    "\n",
    "        # In[246]:\n",
    "\n",
    "\n",
    "        try:\n",
    "         df_playerstats.to_sql(name='PlayerStats', con=engine, if_exists='replace', index=False)\n",
    "        except Exception as e: print(e)\n",
    "\n",
    "\n",
    "        # In[247]:\n",
    "\n",
    "\n",
    "        try:\n",
    "         df_transferhistory.to_sql(name='TransferHistory', con=engine, if_exists='replace', index=False)\n",
    "        except Exception as e: print(e)\n",
    "\n",
    "\n",
    "        # In[248]:\n",
    "\n",
    "\n",
    "\n",
    "        # In[251]:\n",
    "\n",
    "\n",
    "        df_Players=pd.read_sql(\"Select * from Players\",cnxn)\n",
    "\n",
    "\n",
    "        # In[252]:\n",
    "\n",
    "\n",
    "        print(df_Players.head())\n",
    "\n",
    "\n",
    "        # In[253]:\n",
    "\n",
    "\n",
    "        df_Teams=pd.read_sql(\"Select * from Teams\",cnxn)\n",
    "\n",
    "\n",
    "        # In[254]:\n",
    "\n",
    "\n",
    "        print(df_Teams.head())\n",
    "\n",
    "\n",
    "        # In[255]:\n",
    "\n",
    "\n",
    "        df_Matches=pd.read_sql(\"Select * from Matches\",cnxn)\n",
    "\n",
    "\n",
    "        # In[256]:\n",
    "\n",
    "\n",
    "        print(df_Matches.head())\n",
    "\n",
    "\n",
    "        # In[257]:\n",
    "\n",
    "\n",
    "        df_PlayerStats=pd.read_sql(\"Select * from PlayerStats\",cnxn)\n",
    "\n",
    "\n",
    "        # In[258]:\n",
    "\n",
    "\n",
    "        print(df_PlayerStats.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PlayerID  TeamID               Name    Position DateOfBirth  Nationality  \\\n",
      "0         1       1   Daniel Hernandez  Midfielder    3/6/1981      Spanish   \n",
      "1         2       1        Henry Brown     Forward    2/6/1991    Brazilian   \n",
      "2         3       1   Alexander Miller  Midfielder   3/30/1985  Argentinian   \n",
      "3         4       1  Michael Hernandez    Defender    8/6/1996      Spanish   \n",
      "4         5       1    Henry Rodriguez     Forward   9/22/1995      English   \n",
      "\n",
      "  ContractUntil  MarketValue  \n",
      "0     6/30/2025      5000000  \n",
      "1     6/30/2023      9000000  \n",
      "2     6/30/2027      2000000  \n",
      "3     6/30/2025     16000000  \n",
      "4     6/30/2024     16000000  \n",
      "   TeamID       TeamName  FoundedYear HomeCity      ManagerName  \\\n",
      "0       1    Roma United         1883     Rome      Marco Rossi   \n",
      "1       2     Milan City         1875    Milan    Carlos Garcia   \n",
      "2       3    Turin Stars         1853    Turin     Franco Conti   \n",
      "3       4      Naples FC         1870   Naples     Luca Bianchi   \n",
      "4       5  Venice Rovers         1948   Venice  Giuseppe Romano   \n",
      "\n",
      "     StadiumName  StadiumCapacity Country  \n",
      "0     Roma Arena            52000   Italy  \n",
      "1  Milan Stadium            50000   Italy  \n",
      "2   Turin Ground            48000   Italy  \n",
      "3    Napoli Park            47000   Italy  \n",
      "4   Venice Field            46000   Italy  \n",
      "   MatchID        Date  HomeTeamID  AwayTeamID  HomeTeamScore  AwayTeamScore  \\\n",
      "0        1   11/6/2023           5          12              2              1   \n",
      "1        2   8/15/2023           8           3              3              3   \n",
      "2        3   9/21/2023           4           9              1              0   \n",
      "3        4  10/11/2023           7          10              0              2   \n",
      "4        5   12/5/2023           6          11              1              1   \n",
      "\n",
      "            Stadium           Referee  \n",
      "0      Venice Field  Mark Clattenburg  \n",
      "1  Marseille Ground         Mike Dean  \n",
      "2       Napoli Park    Anthony Taylor  \n",
      "3        Lyon Arena    Michael Oliver  \n",
      "4     Paris Stadium   Martin Atkinson  \n",
      "   StatID  PlayerID  MatchID  Goals  Assists  YellowCards  RedCards  \\\n",
      "0       1       317       56      0      NaN            0         0   \n",
      "1       2       290      114      3      NaN            0         0   \n",
      "2       3       162       54      1      NaN            0         0   \n",
      "3       4        87       84      1      NaN            1         0   \n",
      "4       6        43       54      0      NaN            1         0   \n",
      "\n",
      "   MinutesPlayed  \n",
      "0             90  \n",
      "1             90  \n",
      "2             45  \n",
      "3             45  \n",
      "4             90  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sweet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\sweet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\sweet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "c:\\Users\\sweet\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "load_incremental_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " def main():\n",
    "    load_incremental_data()\n",
    "        \n",
    "    # Log File Setup\n",
    "\n",
    "    # In[324]:\n",
    "\n",
    "\n",
    "    import logging\n",
    "\n",
    "    logging.basicConfig(\n",
    "        filename='data_quality_log.txt',\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "\n",
    "\n",
    "    # Number of Records before Cleaning\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "    # df_Table=[df_Players,df_Teams,df_Matches,df_PlayerStats,df_TransferHistory]\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "    # for table in df_Table:\n",
    "    #     record_count = len(table)\n",
    "    #     logging.info(f'Data loaded from {table} table . Number of records Before Data Cleaning: {record_count}')\n",
    "\n",
    "\n",
    "    # Data Cleaning and Quality Checks\n",
    "\n",
    "    # 1.Cleansing of player table\n",
    "\n",
    "    # In[262]:\n",
    "\n",
    "\n",
    "    df_Players.info()\n",
    "\n",
    "\n",
    "    # In[264]:\n",
    "\n",
    "\n",
    "    df_Players['MarketValue'].describe()\n",
    "\n",
    "\n",
    "    # In[265]:\n",
    "\n",
    "\n",
    "    df_Players.isna().sum()\n",
    "\n",
    "\n",
    "    # In[266]:\n",
    "\n",
    "\n",
    "    df_Players['DateOfBirth'] = pd.to_datetime(df_Players['DateOfBirth'], errors='coerce')\n",
    "    df_Players['ContractUntil'] = pd.to_datetime(df_Players['ContractUntil'], errors='coerce')\n",
    "\n",
    "\n",
    "    # In[267]:\n",
    "\n",
    "\n",
    "    # check Consistency between team and player team id\n",
    "    print(df_Teams.columns)\n",
    "\n",
    "\n",
    "    # In[268]:\n",
    "\n",
    "\n",
    "    valid_team_ids = df_Teams['TeamID'].tolist()\n",
    "    invalid_team_ids = df_Players[~df_Players['TeamID'].isin(valid_team_ids)]\n",
    "\n",
    "\n",
    "    # detecting outlieries in market value\n",
    "\n",
    "    # In[269]:\n",
    "\n",
    "\n",
    "    import plotly.express as px\n",
    "\n",
    "\n",
    "    fig = px.box(df_Players, y='MarketValue', title='Market Value Distribution of Players')\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    # In[270]:\n",
    "\n",
    "\n",
    "    errors_df_player = invalid_team_ids\n",
    "    df_cleaned_Players = df_Players.drop(errors_df_player.index)\n",
    "\n",
    "\n",
    "    # loging number of player records before and after\n",
    "\n",
    "    # In[271]:\n",
    "\n",
    "\n",
    "    print(f'Original number of records: {len(df_Players)}')\n",
    "    print(f'Number of records after cleaning: {len(df_cleaned_Players)}')\n",
    "\n",
    "\n",
    "    # In[273]:\n",
    "\n",
    "\n",
    "    logging.info(f'Players table: {len(df_Players)} records before cleaning, {len(df_cleaned_Players)} records after cleaning.')\n",
    "\n",
    "\n",
    "    # 2.Cleansing of df_TransferHistory table\n",
    "\n",
    "    # In[274]:\n",
    "\n",
    "\n",
    "    df_TransferHistory.info()\n",
    "\n",
    "\n",
    "    # In[275]:\n",
    "\n",
    "\n",
    "    df_TransferHistory.isna().sum()\n",
    "\n",
    "\n",
    "    # In[276]:\n",
    "\n",
    "\n",
    "    df_TransferHistory['ContractDuration'].describe()\n",
    "\n",
    "\n",
    "    # In[277]:\n",
    "\n",
    "\n",
    "    df_TransferHistory.isna().sum()\n",
    "\n",
    "\n",
    "    # In[278]:\n",
    "\n",
    "\n",
    "    df_TransferHistory.columns\n",
    "\n",
    "\n",
    "    # detecting outlier in countract transfer of of player history\n",
    "\n",
    "    # In[279]:\n",
    "\n",
    "\n",
    "    import plotly.express as px\n",
    "    fig = px.box(df_TransferHistory, y='ContractDuration', title='ContractDuration Distribution of Players Trnsfers')\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    # In[280]:\n",
    "\n",
    "\n",
    "    q1 = df_TransferHistory['ContractDuration'].quantile(0.25)\n",
    "    q3 = df_TransferHistory['ContractDuration'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "\n",
    "    outliers = df_TransferHistory[(df_TransferHistory['ContractDuration'] < lower_bound) | \n",
    "                                (df_TransferHistory['ContractDuration'] > upper_bound)]\n",
    "\n",
    "\n",
    "    error_df_TransferHistory = outliers.copy()\n",
    "\n",
    "\n",
    "    df_cleaned_TransferHistory = df_TransferHistory.drop(outliers.index)\n",
    "\n",
    "\n",
    "    # In[281]:\n",
    "\n",
    "\n",
    "    # check duplicate \n",
    "    duplicates = df_TransferHistory.duplicated()\n",
    "    error_df_TransferHistory = df_TransferHistory[duplicates]\n",
    "    df_cleaned_TransferHistory = df_TransferHistory.drop_duplicates()\n",
    "\n",
    "\n",
    "    # In[282]:\n",
    "\n",
    "\n",
    "    df_TransferHistory['TransferDate'] = pd.to_datetime(df_TransferHistory['TransferDate'], errors='coerce')\n",
    "\n",
    "\n",
    "    # In[283]:\n",
    "\n",
    "\n",
    "    # check id integrity\n",
    "    invalid_player_ids = df_TransferHistory[~df_TransferHistory['PlayerID'].isin(df_Players['PlayerID'])]\n",
    "    invalid_from_team_ids = df_TransferHistory[~df_TransferHistory['FromTeamID'].isin(df_Teams['TeamID'])]\n",
    "    invalid_to_team_ids = df_TransferHistory[~df_TransferHistory['ToTeamID'].isin(df_Teams['TeamID'])]\n",
    "\n",
    "    error_df_TransferHistory = pd.concat([invalid_player_ids, invalid_from_team_ids, invalid_to_team_ids]).drop_duplicates()\n",
    "    df_cleaned_TransferHistory = df_TransferHistory.drop(error_df_TransferHistory.index)\n",
    "\n",
    "\n",
    "    # In[286]:\n",
    "\n",
    "\n",
    "    logging.info(f'Original number of records  in TransferHistory: {len(df_TransferHistory)}')\n",
    "    logging.info(f'Number of outliers removed from TransferHistory: {len(outliers)}')\n",
    "    logging.info(f'Number of records after cleaning TransferHistory: {len(df_cleaned_TransferHistory)}')\n",
    "\n",
    "\n",
    "    # 3.df_PlayerStats cleansing\n",
    "\n",
    "    # In[287]:\n",
    "\n",
    "\n",
    "    df_PlayerStats.info()\n",
    "\n",
    "\n",
    "    # In[288]:\n",
    "\n",
    "\n",
    "    df_PlayerStats.isna().sum()\n",
    "\n",
    "\n",
    "    # In[289]:\n",
    "\n",
    "\n",
    "    df_PlayerStats.describe()\n",
    "\n",
    "\n",
    "    # In[290]:\n",
    "\n",
    "\n",
    "    error_df_PlayerStats= df_PlayerStats[df_PlayerStats['Assists'].isna()]\n",
    "\n",
    "\n",
    "    # In[291]:\n",
    "\n",
    "\n",
    "    df_cleaned_PlayerStats = df_PlayerStats.dropna(subset=['Assists'])\n",
    "\n",
    "\n",
    "    # In[292]:\n",
    "\n",
    "\n",
    "    fig_yellow_cards = px.box(df_cleaned_PlayerStats, y='YellowCards', title=\"Yellow Cards Distribution\")\n",
    "    fig_yellow_cards.show()\n",
    "\n",
    "\n",
    "    # In[293]:\n",
    "\n",
    "\n",
    "    fig_red_cards = px.box(df_cleaned_PlayerStats, y='RedCards', title=\"Red Cards Distribution\")\n",
    "    fig_red_cards.show()\n",
    "\n",
    "\n",
    "    # In[294]:\n",
    "\n",
    "\n",
    "    # Identify records that violate the rule: RedCards should only occur if YellowCards >= 2\n",
    "    invalid_records = df_cleaned_PlayerStats[(df_cleaned_PlayerStats['RedCards'] > 0) & (df_cleaned_PlayerStats['YellowCards'] < 2)]\n",
    "\n",
    "\n",
    "    valid_records = df_cleaned_PlayerStats.drop(invalid_records.index)\n",
    "\n",
    "\n",
    "    eerror_df_PlayerStats = invalid_records.copy()\n",
    "\n",
    "\n",
    "    df_cleaned_PlayerStats = valid_records.copy()\n",
    "\n",
    "\n",
    "    # In[295]:\n",
    "\n",
    "\n",
    "    fig_scatter = px.scatter(df_cleaned_PlayerStats, x='YellowCards', y='RedCards', title=\"Yellow vs. Red Cards Scatter Plot\")\n",
    "    fig_scatter.show()\n",
    "\n",
    "\n",
    "    # In[296]:\n",
    "\n",
    "\n",
    "    logging.info(f\"Number of records of Player Stats before data cleansing: {len(df_PlayerStats)}\")\n",
    "    logging.info(f\"Number of records of Player Stats after data cleansing: {len(df_cleaned_PlayerStats)}\")\n",
    "\n",
    "\n",
    "    # 4. Team Table Cleansing\n",
    "\n",
    "    # In[297]:\n",
    "\n",
    "\n",
    "    df_Teams.info()\n",
    "\n",
    "\n",
    "    # In[298]:\n",
    "\n",
    "\n",
    "    df_Teams.isna().sum()\n",
    "\n",
    "\n",
    "    # In[299]:\n",
    "\n",
    "\n",
    "    df_Teams.describe()\n",
    "\n",
    "\n",
    "    # In[300]:\n",
    "\n",
    "\n",
    "    duplicated_data=df_Teams.duplicated()\n",
    "\n",
    "\n",
    "    # In[301]:\n",
    "\n",
    "\n",
    "    df_Teams_error=duplicated_data\n",
    "\n",
    "\n",
    "    # In[302]:\n",
    "\n",
    "\n",
    "    df_Teams_Cleaned=df_Teams\n",
    "\n",
    "\n",
    "    # In[303]:\n",
    "\n",
    "\n",
    "    logging.info(f\"Number of records of Teams before data cleansing: {len(df_Teams)}\")\n",
    "    logging.info(f\"Number of records of Teams after data cleansing: {len(df_Teams_Cleaned)}\")\n",
    "\n",
    "\n",
    "    # 5.Matches Table Cleaning\n",
    "\n",
    "    # In[304]:\n",
    "\n",
    "\n",
    "    df_Matches.info()\n",
    "\n",
    "\n",
    "    # In[305]:\n",
    "\n",
    "\n",
    "    df_Matches.isna().sum()\n",
    "\n",
    "\n",
    "    # In[306]:\n",
    "\n",
    "\n",
    "    df_Matches.describe()\n",
    "\n",
    "\n",
    "    # In[307]:\n",
    "\n",
    "\n",
    "    df_Cleaned_Matches= df_Matches.copy()\n",
    "    df_Error_Matches = pd.DataFrame(columns=df_Matches.columns.tolist() + ['ErrorType'])\n",
    "\n",
    "\n",
    "    # In[308]:\n",
    "\n",
    "\n",
    "    logging.info(f\"Number of records of dMatches before data cleansing: {len(df_Matches)}\")\n",
    "    logging.info(f\"Number of records of Matches after data cleansing: {len(df_Cleaned_Matches)}\")\n",
    "\n",
    "\n",
    "    # step 3 data storage\n",
    "\n",
    "    # In[163]:\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    # In[309]:\n",
    "\n",
    "\n",
    "    print(df_cleaned_Players)\n",
    "\n",
    "\n",
    "    # In[310]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        df_cleaned_Players.to_sql(name='df_cleaned_Players', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # In[311]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        errors_df_player.to_sql(name='errors_df_player', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # In[312]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        df_cleaned_TransferHistory.to_sql(name='df_cleaned_TransferHistory', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # In[313]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        error_df_TransferHistory.to_sql(name='error_df_TransferHistory', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # In[314]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        df_cleaned_PlayerStats.to_sql(name='df_cleaned_PlayerStats', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # In[315]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        eerror_df_PlayerStats.to_sql(name='eerror_df_PlayerStats', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # In[316]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        df_Teams_Cleaned.to_sql(name='df_Teams_Cleaned', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # In[317]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        df_Teams_error.to_sql(name='df_Teams_error', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # In[318]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        df_Error_Matches.to_sql(name='df_Error_Matches', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # In[319]:\n",
    "\n",
    "\n",
    "    try:\n",
    "        df_Cleaned_Matches.to_sql(name='df_Cleaned_Matches', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "\n",
    "    # 4. View Population\n",
    "\n",
    "    # In[320]:\n",
    "\n",
    "\n",
    "    df_players = pd.read_sql(\"SELECT * FROM df_cleaned_Players\", cnxn)\n",
    "    df_player_stats = pd.read_sql(\"SELECT * FROM df_cleaned_PlayerStats\", cnxn)\n",
    "    df_transfer_history = pd.read_sql(\"SELECT * FROM df_cleaned_TransferHistory\", cnxn)\n",
    "    df_teams = pd.read_sql(\"SELECT * FROM df_Teams_Cleaned\", cnxn)\n",
    "    df_matches = pd.read_sql(\"SELECT * FROM df_Cleaned_Matches\", cnxn)\n",
    "\n",
    "\n",
    "    # In[321]:\n",
    "\n",
    "\n",
    "    view_name = \"PlayerPerformanceView_New\"\n",
    "\n",
    "    # Drop the view if it already exists\n",
    "    drop_view_query = f\"IF OBJECT_ID('{view_name}', 'V') IS NOT NULL DROP VIEW {view_name};\"\n",
    "    cnxn.execute(drop_view_query)\n",
    "\n",
    "\n",
    "    # In[322]:\n",
    "\n",
    "\n",
    "    create_view_query = f\"\"\"\n",
    "    CREATE VIEW {view_name} AS\n",
    "    WITH PlayerStatsSummary AS (\n",
    "        SELECT\n",
    "            p.PlayerID,\n",
    "            p.Name AS PlayerName,\n",
    "            t.TeamName AS CurrentTeam,\n",
    "            ISNULL(SUM(ps.Goals), 0) AS TotalGoals,\n",
    "            ISNULL(SUM(ps.Assists), 0) AS TotalAssists,\n",
    "            ISNULL(AVG(ps.MinutesPlayed), 0) AS AverageMinutesPlayed,\n",
    "            ISNULL(SUM(ps.MinutesPlayed), 0) AS TotalMinutesPlayed,\n",
    "            MAX(ps.Goals) AS MaxGoalsInMatch,\n",
    "            DATEDIFF(YEAR, p.DateOfBirth, GETDATE()) AS Age\n",
    "        FROM\n",
    "            df_cleaned_Players p\n",
    "            INNER JOIN df_Teams_Cleaned t ON p.TeamID = t.TeamID\n",
    "            LEFT JOIN df_cleaned_PlayerStats ps ON p.PlayerID = ps.PlayerID\n",
    "        GROUP BY\n",
    "            p.PlayerID, p.Name, t.TeamName, p.DateOfBirth\n",
    "    )\n",
    "    SELECT\n",
    "        pss.PlayerID,\n",
    "        pss.PlayerName,\n",
    "        pss.CurrentTeam,\n",
    "        pss.TotalGoals,\n",
    "        pss.TotalAssists,\n",
    "        pss.AverageMinutesPlayed,\n",
    "        CASE WHEN pss.TotalMinutesPlayed > 300 THEN 1 ELSE 0 END AS PlayedOver300Min,\n",
    "        CASE WHEN pss.Age BETWEEN 25 AND 30 THEN 1 ELSE 0 END AS AgeBetween25And30,\n",
    "        CASE WHEN pss.MaxGoalsInMatch >= 3 THEN 1 ELSE 0 END AS Scored3PlusGoalsInMatch,\n",
    "        CONCAT(FLOOR(pss.TotalMinutesPlayed / 90), ' match ', pss.TotalMinutesPlayed % 90, ' min') AS EstimatedMatchesPlayed,\n",
    "        CASE WHEN th_fr.PlayerID IS NOT NULL THEN 1 ELSE 0 END AS PlayedInFrance,\n",
    "        th_fr.DateJoined AS DateJoinedFrenchTeam,\n",
    "        CASE WHEN th_it.PlayerID IS NOT NULL THEN 1 ELSE 0 END AS PlayedInItaly,\n",
    "        th_it.DateJoined AS DateJoinedItalianTeam\n",
    "    FROM\n",
    "        PlayerStatsSummary pss\n",
    "        LEFT JOIN (\n",
    "            SELECT th.PlayerID, MIN(th.TransferDate) AS DateJoined\n",
    "            FROM df_cleaned_TransferHistory th\n",
    "            INNER JOIN df_Teams_Cleaned tf ON th.FromTeamID = tf.TeamID OR th.ToTeamID = tf.TeamID\n",
    "            WHERE tf.Country = 'France'\n",
    "            GROUP BY th.PlayerID\n",
    "        ) th_fr ON pss.PlayerID = th_fr.PlayerID\n",
    "        LEFT JOIN (\n",
    "            SELECT th.PlayerID, MIN(th.TransferDate) AS DateJoined\n",
    "            FROM df_cleaned_TransferHistory th\n",
    "            INNER JOIN df_Teams_Cleaned ti ON th.FromTeamID = ti.TeamID OR th.ToTeamID = ti.TeamID\n",
    "            WHERE ti.Country = 'Italy'\n",
    "            GROUP BY th.PlayerID\n",
    "        ) th_it ON pss.PlayerID = th_it.PlayerID;\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    cursor.execute(create_view_query)\n",
    "\n",
    "    print(f\"View '{view_name}' created successfully.\")\n",
    "\n",
    "\n",
    "    # In[323]:\n",
    "\n",
    "\n",
    "    df_view = pd.read_sql(f\"SELECT * FROM {view_name}\", cnxn)\n",
    "    print(df_view.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Players' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 40\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(\n\u001b[0;32m     11\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_quality_log.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Number of Records before Cleaning\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# In[ ]:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# In[262]:\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mdf_Players\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# In[264]:\u001b[39;00m\n\u001b[0;32m     46\u001b[0m df_Players[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarketValue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_Players' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
